{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask R-CNN - Train on Shapes Dataset\n",
    "\n",
    "\n",
    "This notebook shows how to train Mask R-CNN on your own dataset. To keep things simple we use a synthetic dataset of shapes (squares, triangles, and circles) which enables fast training. You'd still need a GPU, though, because the network backbone is a Resnet101, which would be too slow to train on a CPU. On a GPU, you can start to get okay-ish results in a few minutes, and good results in less than an hour.\n",
    "\n",
    "The code of the *Shapes* dataset is included below. It generates images on the fly, so it doesn't require downloading any data. And it can generate images of any size, so we pick a small image size to train faster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../../\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     8\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 8\n",
      "IMAGE_MAX_DIM                  128\n",
      "IMAGE_META_SIZE                16\n",
      "IMAGE_MIN_DIM                  128\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [128 128   3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           shapes\n",
      "NUM_CLASSES                    4\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                100\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           32\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               5\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class ShapesConfig(Config):\n",
    "    \"\"\"Configuration for training on the toy shapes dataset.\n",
    "    Derives from the base Config class and overrides values specific\n",
    "    to the toy shapes dataset.\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"shapes\"\n",
    "\n",
    "    # Train on 1 GPU and 8 images per GPU. We can put multiple images on each\n",
    "    # GPU because the images are small. Batch size is 8 (GPUs * images/GPU).\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 8\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 3  # background + 3 shapes\n",
    "\n",
    "    # Use small images for faster training. Set the limits of the small side\n",
    "    # the large side, and that determines the image shape.\n",
    "    IMAGE_MIN_DIM = 128\n",
    "    IMAGE_MAX_DIM = 128\n",
    "\n",
    "    # Use smaller anchors because our image and objects are small\n",
    "    RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)  # anchor side in pixels\n",
    "\n",
    "    # Reduce training ROIs per image because the images are small and have\n",
    "    # few objects. Aim to allow ROI sampling to pick 33% positive ROIs.\n",
    "    TRAIN_ROIS_PER_IMAGE = 32\n",
    "\n",
    "    # Use a small epoch since the data is simple\n",
    "    STEPS_PER_EPOCH = 100\n",
    "\n",
    "    # use small validation steps since the epoch is small\n",
    "    VALIDATION_STEPS = 5\n",
    "    \n",
    "config = ShapesConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Create a synthetic dataset\n",
    "\n",
    "Extend the Dataset class and add a method to load the shapes dataset, `load_shapes()`, and override the following methods:\n",
    "\n",
    "* load_image()\n",
    "* load_mask()\n",
    "* image_reference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapesDataset(utils.Dataset):\n",
    "    \"\"\"Generates the shapes synthetic dataset. The dataset consists of simple\n",
    "    shapes (triangles, squares, circles) placed randomly on a blank surface.\n",
    "    The images are generated on the fly. No file access required.\n",
    "    \"\"\"\n",
    "\n",
    "    def load_shapes(self, count, height, width):\n",
    "        \"\"\"Generate the requested number of synthetic images.\n",
    "        count: number of images to generate.\n",
    "        height, width: the size of the generated images.\n",
    "        \"\"\"\n",
    "        # Add classes\n",
    "        self.add_class(\"shapes\", 1, \"square\")\n",
    "        self.add_class(\"shapes\", 2, \"circle\")\n",
    "        self.add_class(\"shapes\", 3, \"triangle\")\n",
    "\n",
    "        # Add images\n",
    "        # Generate random specifications of images (i.e. color and\n",
    "        # list of shapes sizes and locations). This is more compact than\n",
    "        # actual images. Images are generated on the fly in load_image().\n",
    "        for i in range(count):\n",
    "            bg_color, shapes = self.random_image(height, width)\n",
    "            self.add_image(\"shapes\", image_id=i, path=None,\n",
    "                           width=width, height=height,\n",
    "                           bg_color=bg_color, shapes=shapes)\n",
    "\n",
    "    def load_image(self, image_id):\n",
    "        \"\"\"Generate an image from the specs of the given image ID.\n",
    "        Typically this function loads the image from a file, but\n",
    "        in this case it generates the image on the fly from the\n",
    "        specs in image_info.\n",
    "        \"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        bg_color = np.array(info['bg_color']).reshape([1, 1, 3])\n",
    "        image = np.ones([info['height'], info['width'], 3], dtype=np.uint8)\n",
    "        image = image * bg_color.astype(np.uint8)\n",
    "        for shape, color, dims in info['shapes']:\n",
    "            image = self.draw_shape(image, shape, dims, color)\n",
    "        return image\n",
    "\n",
    "    def image_reference(self, image_id):\n",
    "        \"\"\"Return the shapes data of the image.\"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == \"shapes\":\n",
    "            return info[\"shapes\"]\n",
    "        else:\n",
    "            super(self.__class__).image_reference(self, image_id)\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"Generate instance masks for shapes of the given image ID.\n",
    "        \"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        shapes = info['shapes']\n",
    "        count = len(shapes)\n",
    "        mask = np.zeros([info['height'], info['width'], count], dtype=np.uint8)\n",
    "        for i, (shape, _, dims) in enumerate(info['shapes']):\n",
    "            mask[:, :, i:i+1] = self.draw_shape(mask[:, :, i:i+1].copy(),\n",
    "                                                shape, dims, 1)\n",
    "        # Handle occlusions\n",
    "        occlusion = np.logical_not(mask[:, :, -1]).astype(np.uint8)\n",
    "        for i in range(count-2, -1, -1):\n",
    "            mask[:, :, i] = mask[:, :, i] * occlusion\n",
    "            occlusion = np.logical_and(occlusion, np.logical_not(mask[:, :, i]))\n",
    "        # Map class names to class IDs.\n",
    "        class_ids = np.array([self.class_names.index(s[0]) for s in shapes])\n",
    "        return mask.astype(np.bool), class_ids.astype(np.int32)\n",
    "\n",
    "    def draw_shape(self, image, shape, dims, color):\n",
    "        \"\"\"Draws a shape from the given specs.\"\"\"\n",
    "        # Get the center x, y and the size s\n",
    "        x, y, s = dims\n",
    "        if shape == 'square':\n",
    "            cv2.rectangle(image, (x-s, y-s), (x+s, y+s), color, -1)\n",
    "        elif shape == \"circle\":\n",
    "            cv2.circle(image, (x, y), s, color, -1)\n",
    "        elif shape == \"triangle\":\n",
    "            points = np.array([[(x, y-s),\n",
    "                                (x-s/math.sin(math.radians(60)), y+s),\n",
    "                                (x+s/math.sin(math.radians(60)), y+s),\n",
    "                                ]], dtype=np.int32)\n",
    "            cv2.fillPoly(image, points, color)\n",
    "        return image\n",
    "\n",
    "    def random_shape(self, height, width):\n",
    "        \"\"\"Generates specifications of a random shape that lies within\n",
    "        the given height and width boundaries.\n",
    "        Returns a tuple of three valus:\n",
    "        * The shape name (square, circle, ...)\n",
    "        * Shape color: a tuple of 3 values, RGB.\n",
    "        * Shape dimensions: A tuple of values that define the shape size\n",
    "                            and location. Differs per shape type.\n",
    "        \"\"\"\n",
    "        # Shape\n",
    "        shape = random.choice([\"square\", \"circle\", \"triangle\"])\n",
    "        # Color\n",
    "        color = tuple([random.randint(0, 255) for _ in range(3)])\n",
    "        # Center x, y\n",
    "        buffer = 20\n",
    "        y = random.randint(buffer, height - buffer - 1)\n",
    "        x = random.randint(buffer, width - buffer - 1)\n",
    "        # Size\n",
    "        s = random.randint(buffer, height//4)\n",
    "        return shape, color, (x, y, s)\n",
    "\n",
    "    def random_image(self, height, width):\n",
    "        \"\"\"Creates random specifications of an image with multiple shapes.\n",
    "        Returns the background color of the image and a list of shape\n",
    "        specifications that can be used to draw the image.\n",
    "        \"\"\"\n",
    "        # Pick random background color\n",
    "        bg_color = np.array([random.randint(0, 255) for _ in range(3)])\n",
    "        # Generate a few random shapes and record their\n",
    "        # bounding boxes\n",
    "        shapes = []\n",
    "        boxes = []\n",
    "        N = random.randint(1, 4)\n",
    "        for _ in range(N):\n",
    "            shape, color, dims = self.random_shape(height, width)\n",
    "            shapes.append((shape, color, dims))\n",
    "            x, y, s = dims\n",
    "            boxes.append([y-s, x-s, y+s, x+s])\n",
    "        # Apply non-max suppression wit 0.3 threshold to avoid\n",
    "        # shapes covering each other\n",
    "        keep_ixs = utils.non_max_suppression(np.array(boxes), np.arange(N), 0.3)\n",
    "        shapes = [s for i, s in enumerate(shapes) if i in keep_ixs]\n",
    "        return bg_color, shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training dataset\n",
    "dataset_train = ShapesDataset()\n",
    "dataset_train.load_shapes(500, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
    "dataset_train.prepare()\n",
    "\n",
    "# Validation dataset\n",
    "dataset_val = ShapesDataset()\n",
    "dataset_val.load_shapes(50, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
    "dataset_val.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load and display random samples\n",
    "image_ids = np.random.choice(dataset_train.image_ids, 4)\n",
    "for image_id in image_ids:\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ceate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model in training mode\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                          model_dir=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Which weights to start with?\n",
    "init_with = \"coco\"  # imagenet, coco, or last\n",
    "\n",
    "if init_with == \"imagenet\":\n",
    "    model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "elif init_with == \"coco\":\n",
    "    # Load weights trained on MS COCO, but skip layers that\n",
    "    # are different due to the different number of classes\n",
    "    # See README for instructions to download the COCO weights\n",
    "    model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
    "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "elif init_with == \"last\":\n",
    "    # Load the last model you trained and continue training\n",
    "    model.load_weights(model.find_last()[1], by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Train in two stages:\n",
    "1. Only the heads. Here we're freezing all the backbone layers and training only the randomly initialized layers (i.e. the ones that we didn't use pre-trained weights from MS COCO). To train only the head layers, pass `layers='heads'` to the `train()` function.\n",
    "\n",
    "2. Fine-tune all layers. For this simple example it's not necessary, but we're including it to show the process. Simply pass `layers=\"all` to train all layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: /home/jinl/code/Mask_RCNN/logs/shapes20180628T0028/mask_rcnn_shapes_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n",
      "WARNING:tensorflow:From /home/jinl/code/Mask_RCNN/mrcnn/model.py:2140: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/keras/engine/training.py:2087: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1.8189 - rpn_class_loss: 0.0319 - rpn_bbox_loss: 0.6165 - mrcnn_class_loss: 0.3778 - mrcnn_bbox_loss: 0.4289 - mrcnn_mask_loss: 0.3638"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/engine/training.py:2348: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "100/100 [==============================] - 78s 777ms/step - loss: 1.8107 - rpn_class_loss: 0.0318 - rpn_bbox_loss: 0.6154 - mrcnn_class_loss: 0.3757 - mrcnn_bbox_loss: 0.4260 - mrcnn_mask_loss: 0.3619 - val_loss: 0.9814 - val_rpn_class_loss: 0.0150 - val_rpn_bbox_loss: 0.3979 - val_mrcnn_class_loss: 0.1740 - val_mrcnn_bbox_loss: 0.1934 - val_mrcnn_mask_loss: 0.2011\n"
     ]
    }
   ],
   "source": [
    "# Train the head branches\n",
    "# Passing layers=\"heads\" freezes all layers except the head\n",
    "# layers. You can also pass a regular expression to select\n",
    "# which layers to train by name pattern.\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE, \n",
    "            epochs=1, \n",
    "            layers='heads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting at epoch 1. LR=0.0001\n",
      "\n",
      "Checkpoint Path: /home/jinl/code/Mask_RCNN/logs/shapes20180628T0028/mask_rcnn_shapes_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "conv1                  (Conv2D)\n",
      "bn_conv1               (BatchNorm)\n",
      "res2a_branch2a         (Conv2D)\n",
      "bn2a_branch2a          (BatchNorm)\n",
      "res2a_branch2b         (Conv2D)\n",
      "bn2a_branch2b          (BatchNorm)\n",
      "res2a_branch2c         (Conv2D)\n",
      "res2a_branch1          (Conv2D)\n",
      "bn2a_branch2c          (BatchNorm)\n",
      "bn2a_branch1           (BatchNorm)\n",
      "res2b_branch2a         (Conv2D)\n",
      "bn2b_branch2a          (BatchNorm)\n",
      "res2b_branch2b         (Conv2D)\n",
      "bn2b_branch2b          (BatchNorm)\n",
      "res2b_branch2c         (Conv2D)\n",
      "bn2b_branch2c          (BatchNorm)\n",
      "res2c_branch2a         (Conv2D)\n",
      "bn2c_branch2a          (BatchNorm)\n",
      "res2c_branch2b         (Conv2D)\n",
      "bn2c_branch2b          (BatchNorm)\n",
      "res2c_branch2c         (Conv2D)\n",
      "bn2c_branch2c          (BatchNorm)\n",
      "res3a_branch2a         (Conv2D)\n",
      "bn3a_branch2a          (BatchNorm)\n",
      "res3a_branch2b         (Conv2D)\n",
      "bn3a_branch2b          (BatchNorm)\n",
      "res3a_branch2c         (Conv2D)\n",
      "res3a_branch1          (Conv2D)\n",
      "bn3a_branch2c          (BatchNorm)\n",
      "bn3a_branch1           (BatchNorm)\n",
      "res3b_branch2a         (Conv2D)\n",
      "bn3b_branch2a          (BatchNorm)\n",
      "res3b_branch2b         (Conv2D)\n",
      "bn3b_branch2b          (BatchNorm)\n",
      "res3b_branch2c         (Conv2D)\n",
      "bn3b_branch2c          (BatchNorm)\n",
      "res3c_branch2a         (Conv2D)\n",
      "bn3c_branch2a          (BatchNorm)\n",
      "res3c_branch2b         (Conv2D)\n",
      "bn3c_branch2b          (BatchNorm)\n",
      "res3c_branch2c         (Conv2D)\n",
      "bn3c_branch2c          (BatchNorm)\n",
      "res3d_branch2a         (Conv2D)\n",
      "bn3d_branch2a          (BatchNorm)\n",
      "res3d_branch2b         (Conv2D)\n",
      "bn3d_branch2b          (BatchNorm)\n",
      "res3d_branch2c         (Conv2D)\n",
      "bn3d_branch2c          (BatchNorm)\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "res4a_branch2c         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2c          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res4b_branch2a         (Conv2D)\n",
      "bn4b_branch2a          (BatchNorm)\n",
      "res4b_branch2b         (Conv2D)\n",
      "bn4b_branch2b          (BatchNorm)\n",
      "res4b_branch2c         (Conv2D)\n",
      "bn4b_branch2c          (BatchNorm)\n",
      "res4c_branch2a         (Conv2D)\n",
      "bn4c_branch2a          (BatchNorm)\n",
      "res4c_branch2b         (Conv2D)\n",
      "bn4c_branch2b          (BatchNorm)\n",
      "res4c_branch2c         (Conv2D)\n",
      "bn4c_branch2c          (BatchNorm)\n",
      "res4d_branch2a         (Conv2D)\n",
      "bn4d_branch2a          (BatchNorm)\n",
      "res4d_branch2b         (Conv2D)\n",
      "bn4d_branch2b          (BatchNorm)\n",
      "res4d_branch2c         (Conv2D)\n",
      "bn4d_branch2c          (BatchNorm)\n",
      "res4e_branch2a         (Conv2D)\n",
      "bn4e_branch2a          (BatchNorm)\n",
      "res4e_branch2b         (Conv2D)\n",
      "bn4e_branch2b          (BatchNorm)\n",
      "res4e_branch2c         (Conv2D)\n",
      "bn4e_branch2c          (BatchNorm)\n",
      "res4f_branch2a         (Conv2D)\n",
      "bn4f_branch2a          (BatchNorm)\n",
      "res4f_branch2b         (Conv2D)\n",
      "bn4f_branch2b          (BatchNorm)\n",
      "res4f_branch2c         (Conv2D)\n",
      "bn4f_branch2c          (BatchNorm)\n",
      "res4g_branch2a         (Conv2D)\n",
      "bn4g_branch2a          (BatchNorm)\n",
      "res4g_branch2b         (Conv2D)\n",
      "bn4g_branch2b          (BatchNorm)\n",
      "res4g_branch2c         (Conv2D)\n",
      "bn4g_branch2c          (BatchNorm)\n",
      "res4h_branch2a         (Conv2D)\n",
      "bn4h_branch2a          (BatchNorm)\n",
      "res4h_branch2b         (Conv2D)\n",
      "bn4h_branch2b          (BatchNorm)\n",
      "res4h_branch2c         (Conv2D)\n",
      "bn4h_branch2c          (BatchNorm)\n",
      "res4i_branch2a         (Conv2D)\n",
      "bn4i_branch2a          (BatchNorm)\n",
      "res4i_branch2b         (Conv2D)\n",
      "bn4i_branch2b          (BatchNorm)\n",
      "res4i_branch2c         (Conv2D)\n",
      "bn4i_branch2c          (BatchNorm)\n",
      "res4j_branch2a         (Conv2D)\n",
      "bn4j_branch2a          (BatchNorm)\n",
      "res4j_branch2b         (Conv2D)\n",
      "bn4j_branch2b          (BatchNorm)\n",
      "res4j_branch2c         (Conv2D)\n",
      "bn4j_branch2c          (BatchNorm)\n",
      "res4k_branch2a         (Conv2D)\n",
      "bn4k_branch2a          (BatchNorm)\n",
      "res4k_branch2b         (Conv2D)\n",
      "bn4k_branch2b          (BatchNorm)\n",
      "res4k_branch2c         (Conv2D)\n",
      "bn4k_branch2c          (BatchNorm)\n",
      "res4l_branch2a         (Conv2D)\n",
      "bn4l_branch2a          (BatchNorm)\n",
      "res4l_branch2b         (Conv2D)\n",
      "bn4l_branch2b          (BatchNorm)\n",
      "res4l_branch2c         (Conv2D)\n",
      "bn4l_branch2c          (BatchNorm)\n",
      "res4m_branch2a         (Conv2D)\n",
      "bn4m_branch2a          (BatchNorm)\n",
      "res4m_branch2b         (Conv2D)\n",
      "bn4m_branch2b          (BatchNorm)\n",
      "res4m_branch2c         (Conv2D)\n",
      "bn4m_branch2c          (BatchNorm)\n",
      "res4n_branch2a         (Conv2D)\n",
      "bn4n_branch2a          (BatchNorm)\n",
      "res4n_branch2b         (Conv2D)\n",
      "bn4n_branch2b          (BatchNorm)\n",
      "res4n_branch2c         (Conv2D)\n",
      "bn4n_branch2c          (BatchNorm)\n",
      "res4o_branch2a         (Conv2D)\n",
      "bn4o_branch2a          (BatchNorm)\n",
      "res4o_branch2b         (Conv2D)\n",
      "bn4o_branch2b          (BatchNorm)\n",
      "res4o_branch2c         (Conv2D)\n",
      "bn4o_branch2c          (BatchNorm)\n",
      "res4p_branch2a         (Conv2D)\n",
      "bn4p_branch2a          (BatchNorm)\n",
      "res4p_branch2b         (Conv2D)\n",
      "bn4p_branch2b          (BatchNorm)\n",
      "res4p_branch2c         (Conv2D)\n",
      "bn4p_branch2c          (BatchNorm)\n",
      "res4q_branch2a         (Conv2D)\n",
      "bn4q_branch2a          (BatchNorm)\n",
      "res4q_branch2b         (Conv2D)\n",
      "bn4q_branch2b          (BatchNorm)\n",
      "res4q_branch2c         (Conv2D)\n",
      "bn4q_branch2c          (BatchNorm)\n",
      "res4r_branch2a         (Conv2D)\n",
      "bn4r_branch2a          (BatchNorm)\n",
      "res4r_branch2b         (Conv2D)\n",
      "bn4r_branch2b          (BatchNorm)\n",
      "res4r_branch2c         (Conv2D)\n",
      "bn4r_branch2c          (BatchNorm)\n",
      "res4s_branch2a         (Conv2D)\n",
      "bn4s_branch2a          (BatchNorm)\n",
      "res4s_branch2b         (Conv2D)\n",
      "bn4s_branch2b          (BatchNorm)\n",
      "res4s_branch2c         (Conv2D)\n",
      "bn4s_branch2c          (BatchNorm)\n",
      "res4t_branch2a         (Conv2D)\n",
      "bn4t_branch2a          (BatchNorm)\n",
      "res4t_branch2b         (Conv2D)\n",
      "bn4t_branch2b          (BatchNorm)\n",
      "res4t_branch2c         (Conv2D)\n",
      "bn4t_branch2c          (BatchNorm)\n",
      "res4u_branch2a         (Conv2D)\n",
      "bn4u_branch2a          (BatchNorm)\n",
      "res4u_branch2b         (Conv2D)\n",
      "bn4u_branch2b          (BatchNorm)\n",
      "res4u_branch2c         (Conv2D)\n",
      "bn4u_branch2c          (BatchNorm)\n",
      "res4v_branch2a         (Conv2D)\n",
      "bn4v_branch2a          (BatchNorm)\n",
      "res4v_branch2b         (Conv2D)\n",
      "bn4v_branch2b          (BatchNorm)\n",
      "res4v_branch2c         (Conv2D)\n",
      "bn4v_branch2c          (BatchNorm)\n",
      "res4w_branch2a         (Conv2D)\n",
      "bn4w_branch2a          (BatchNorm)\n",
      "res4w_branch2b         (Conv2D)\n",
      "bn4w_branch2b          (BatchNorm)\n",
      "res4w_branch2c         (Conv2D)\n",
      "bn4w_branch2c          (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/keras/engine/training.py:2087: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.8692 - rpn_class_loss: 0.0158 - rpn_bbox_loss: 0.4063 - mrcnn_class_loss: 0.1525 - mrcnn_bbox_loss: 0.1275 - mrcnn_mask_loss: 0.1671"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/engine/training.py:2348: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "100/100 [==============================] - 103s 1s/step - loss: 0.8680 - rpn_class_loss: 0.0158 - rpn_bbox_loss: 0.4060 - mrcnn_class_loss: 0.1525 - mrcnn_bbox_loss: 0.1271 - mrcnn_mask_loss: 0.1665 - val_loss: 0.8367 - val_rpn_class_loss: 0.0152 - val_rpn_bbox_loss: 0.4319 - val_mrcnn_class_loss: 0.1319 - val_mrcnn_bbox_loss: 0.1082 - val_mrcnn_mask_loss: 0.1495\n"
     ]
    }
   ],
   "source": [
    "# Fine tune all layers\n",
    "# Passing layers=\"all\" trains all layers. You can also \n",
    "# pass a regular expression to select which layers to\n",
    "# train by name pattern.\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE / 10,\n",
    "            epochs=2, \n",
    "            layers=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save weights\n",
    "# Typically not needed because callbacks save after every epoch\n",
    "# Uncomment to save manually\n",
    "MODEL_DIR = \"/tmp\"\n",
    "model_path = os.path.join(MODEL_DIR, \"mask_rcnn_shapes.h5\")\n",
    "model.keras_model.save_weights(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from  /home/jinl/code/Mask_RCNN/logs/shapes20180628T0028/mask_rcnn_shapes_0002.h5\n"
     ]
    }
   ],
   "source": [
    "class InferenceConfig(ShapesConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "\n",
    "# Recreate the model in inference mode\n",
    "model = modellib.MaskRCNN(mode=\"inference\", \n",
    "                          config=inference_config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "\n",
    "# Get path to saved weights\n",
    "# Either set a specific path or find last trained weights\n",
    "# model_path = os.path.join(ROOT_DIR, \".h5 file name here\")\n",
    "model_path = model.find_last()[1]\n",
    "\n",
    "# Load trained weights (fill in path to trained weights here)\n",
    "assert model_path != \"\", \"Provide path to trained weights\"\n",
    "print(\"Loading weights from \", model_path)\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_image           shape: (128, 128, 3)         min:   30.00000  max:  190.00000  uint8\n",
      "image_meta               shape: (16,)                 min:    0.00000  max:  128.00000  int64\n",
      "gt_class_id              shape: (1,)                  min:    3.00000  max:    3.00000  int32\n",
      "gt_bbox                  shape: (1, 4)                min:   30.00000  max:   78.00000  int32\n",
      "gt_mask                  shape: (128, 128, 1)         min:    0.00000  max:    1.00000  bool\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test on a random image\n",
    "image_id = random.choice(dataset_val.image_ids)\n",
    "original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "    modellib.load_image_gt(dataset_val, inference_config, \n",
    "                           image_id, use_mini_mask=False)\n",
    "\n",
    "log(\"original_image\", original_image)\n",
    "log(\"image_meta\", image_meta)\n",
    "log(\"gt_class_id\", gt_class_id)\n",
    "log(\"gt_bbox\", gt_bbox)\n",
    "log(\"gt_mask\", gt_mask)\n",
    "\n",
    "visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
    "                            dataset_train.class_names, figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1 images\n",
      "image                    shape: (128, 128, 3)         min:   30.00000  max:  190.00000  uint8\n",
      "molded_images            shape: (1, 128, 128, 3)      min:  -86.80000  max:   79.10000  float64\n",
      "image_metas              shape: (1, 16)               min:    0.00000  max:  128.00000  int64\n",
      "anchors                  shape: (1, 4092, 4)          min:   -0.71267  max:    1.20874  float32\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = model.detect([original_image], verbose=1)\n",
    "\n",
    "r = results[0]\n",
    "visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
    "                            dataset_val.class_names, r['scores'], ax=get_ax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP:  0.9666666686534882\n"
     ]
    }
   ],
   "source": [
    "# Compute VOC-Style mAP @ IoU=0.5\n",
    "# Running on 10 images. Increase for better accuracy.\n",
    "image_ids = np.random.choice(dataset_val.image_ids, 10)\n",
    "APs = []\n",
    "for image_id in image_ids:\n",
    "    # Load image and ground truth data\n",
    "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "        modellib.load_image_gt(dataset_val, inference_config,\n",
    "                               image_id, use_mini_mask=False)\n",
    "    molded_images = np.expand_dims(modellib.mold_image(image, inference_config), 0)\n",
    "    # Run object detection\n",
    "    results = model.detect([image], verbose=0)\n",
    "    r = results[0]\n",
    "    # Compute AP\n",
    "    AP, precisions, recalls, overlaps =\\\n",
    "        utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
    "                         r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
    "    APs.append(AP)\n",
    "    \n",
    "print(\"mAP: \", np.mean(APs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
